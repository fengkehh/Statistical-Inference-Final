---
title: "Statistical Inference Project Part 1: Exponential Distribution and Central Limit Theorem"
author: "Keh-Harng Feng"
date: "March 6, 2017"
output: 
    html_document:
        keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview
A computer simulation of random variables following an exponetial distribution is carried out. The means of the simulated variable are computed and plotted. The result follows the prediction using the Central Limit Theorem.

## Introduction

Exponential distribution is a probability distribution that has a pdf described by the function

$$ 
f(x) = 
\begin{cases}
    \lambda e^{- \lambda x}, & x \ge 0\\
    0, & x\lt 0
\end{cases}
$$
where \lambda is the only parameter of the distribution.  It is often referred to as the *rate*. 

The theoretical expected value or mean of the distribution can be found by evaluating the improper integral of the pdf from x = 0 to x = $\infty$ using integration by parts:

$$ E[X] = \frac{1}{\lambda}$$

Similarly, the theoretical variance and standard deviation are found to be:

$$ 
\sigma^2[X] = \frac{1}{\lambda^2} \\
\sigma[X] = \frac{1}{\lambda}
$$

This part of the report uses a computer simulation in R to generate a set of random data following the exponential distribution in order to test the **central limit theorem**  (CLT).

## Central Limit Theorem (CLT)

From [Investopedia](http://www.investopedia.com/terms/c/central_limit_theorem.asp):

The central limit theorem (CLT) is a statistical theory that states that given a sufficiently large sample size from a population with a finite level of variance, the mean of all samples from the same population will be approximately equal to the mean of the population. Furthermore, all of the samples will follow an approximate normal distribution pattern, with all variances being approximately equal to the variance of the population divided by each sample's size.


## Simulations

For the purpose of this report, all simulations for the exponential distribution are computed with the rate, $\lambda$, set to 0.2.

```{r data}
lambda <- 0.2
```

Three matrices with sizes 40 x 10, 40 x 100 and 40 x 1000 are created by filling each column with a random sample of 40 measurements that follow the exponential distribution for a number of samples corresponding to the number of columns in each matrix:

```{r samples}
# Setting fixed seed first for reproducibility.
set.seed(123)

samples_10 <- matrix(data = rexp(40*10, rate = lambda), nrow = 40, ncol = 10)

set.seed(321)
samples_100 <- matrix(data = rexp(40*100, rate = lambda), nrow = 40, ncol = 100)

set.seed(132)
samples_1000 <- matrix(data = rexp(40*1000, rate = lambda), nrow = 40, ncol = 1000)
```

The sample means and sample standard variances are computed as follows:

```{r sample_stats}

sample_means_10 <- apply(samples_10, 2, mean)
sample_vars_10 <- apply(samples_10, 2, var)
sample_sds_10 <- sqrt(samples_10)

sample_means_100 <- apply(samples_100, 2, mean)
sample_vars_100 <- apply(samples_100, 2, var)
sample_sds_100 <- sqrt(samples_100)

sample_means_1000 <- apply(samples_1000, 2, mean)
sample_vars_1000 <- apply(samples_1000, 2, var)
sample_sds_1000 <- sqrt(samples_1000)
```

## Sample Mean versus Theoretical Mean

Since lambda is known we can compute the theoretical mean and variance.

```{r theoretical}
mean_t <- 1/lambda
var_t <- 1/lambda^2
```

The numerical value of the theoretical mean is `r mean_t`. This is superimposed on the distribution of sample means below:

```{r mean_figure}
par(mfrow = c(1,3))
hist(sample_means_10, xlab = 'Sample Mean Distribution', main = '10 samples')
abline(v = mean_t, col = 'red')
mean_10 <- mean(sample_means_10)
abline(v = mean_10, col = 'green')

hist(sample_means_100, xlab = 'Sample Mean Distribution', main = '100 samples')
abline(v = mean_t, col = 'red')
mean_100 <- mean(sample_means_100)
abline(v = mean_100, col = 'green')

hist(sample_means_1000, xlab = 'Sample Mean Distribution', main = '1000 samples')
abline(v = mean_t, col = 'red')
mean_1000 <- mean(sample_means_1000)
abline(v = mean_1000, col = 'green')
legend('center', c('Sample Means', 'Theoretical Mean', 'Average of Sample Means'), lty = c(1,1,1), col = c('black', 'red', 'green'))
```

Qualitatively, it is clear that as the number of samples goes up, the distribution of sample means starts to resemble a normal distribution centered around the theoretical mean more and more. It should also be noted that with 1000 samples the average of the sample means is so close to the theoretical value the two lines are literally right on top of each other (average sample mean = `r mean_1000`).

## Sample Variance versus Theoretical Variance

The numerical value of the theoretical variance is `r var_t`. Once again this is superimposed on the distribution of sample variances below:

```{r var_figure}
par(mfrow = c(1,3))
hist(sample_vars_10, xlab = 'Sample Variance Distribution', main = '10 samples')
abline(v = var_t, col = 'red')
var_10 <- mean(sample_vars_10)
abline(v = var_10, col = 'green')

hist(sample_vars_100, xlab = 'Sample Variance Distribution', main = '100 samples')
abline(v = var_t, col = 'red')
var_100 <- mean(sample_vars_100)
abline(v = var_100, col = 'green')

hist(sample_vars_1000, xlab = 'Sample Variance Distribution', main = '1000 samples')
abline(v = var_t, col = 'red')
var_1000 <- mean(sample_vars_1000)
abline(v = var_1000, col = 'green')
legend('center', c('Sample Variances', 'Theoretical Variance', 'Average of Sample Variances'), lty = c(1,1,1), col = c('black', 'red', 'green'))
```

Similar to the sample means, as the number of samples increases the distribution of sample variances seems to approach that of a normal distribution. The average of the sample variances also approaches the theoretical value. Again, the values are so close for the 1000-sample case (average sample variance = `r var_1000`) the two lines seem to overlap each other. The convergence of average sample mean and average sample variance to the theoretical values is expected, since they are both unbiased statistics.

## Distribution Identification

This section redoubles effort to provide more qualitative evidence that supports the CLT while also verifying the second part of the theorem. That is, the distribution of the sample mean is a normal distribution with $Var[x] = \frac{\sigma^2(x)}{n}$ where $\sigma^2(x)$ is the true variance of the population. 

```{r norm_compare}
```

```{r qq}
qqnorm(sample_means_1000)
qqline(sample_means_1000)
```